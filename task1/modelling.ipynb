{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/BA_reviews_lemmatized.csv', converters={'reviews':pd.eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_verification</th>\n",
       "      <th>reviews</th>\n",
       "      <th>num_words</th>\n",
       "      <th>review_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>['I', 'travel', 'British', 'Airways', 'Sweden'...</td>\n",
       "      <td>196</td>\n",
       "      <td>I travel British Airways Sweden Los Angeles Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>['Food', 'lousy.', 'Who', 'plan', 'Asian', 'Hi...</td>\n",
       "      <td>54</td>\n",
       "      <td>Food lousy. Who plan Asian Hindu Vegetarian me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>['Had', 'worst', 'experience.', 'The', 'flight...</td>\n",
       "      <td>59</td>\n",
       "      <td>Had worst experience. The flight London Toront...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>['The', 'grind', 'staff', 'helpful.', 'Felt', ...</td>\n",
       "      <td>32</td>\n",
       "      <td>The grind staff helpful. Felt like want rush c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>['Second', 'time', 'BA', 'Premium', 'Economy',...</td>\n",
       "      <td>50</td>\n",
       "      <td>Second time BA Premium Economy newer aircraft ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_verification                                            reviews  \\\n",
       "0              False  ['I', 'travel', 'British', 'Airways', 'Sweden'...   \n",
       "1              False  ['Food', 'lousy.', 'Who', 'plan', 'Asian', 'Hi...   \n",
       "2               True  ['Had', 'worst', 'experience.', 'The', 'flight...   \n",
       "3               True  ['The', 'grind', 'staff', 'helpful.', 'Felt', ...   \n",
       "4               True  ['Second', 'time', 'BA', 'Premium', 'Economy',...   \n",
       "\n",
       "   num_words                                    review_sentence  \n",
       "0        196  I travel British Airways Sweden Los Angeles Lo...  \n",
       "1         54  Food lousy. Who plan Asian Hindu Vegetarian me...  \n",
       "2         59  Had worst experience. The flight London Toront...  \n",
       "3         32  The grind staff helpful. Felt like want rush c...  \n",
       "4         50  Second time BA Premium Economy newer aircraft ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "df['Scores'] = df['review_sentence'].apply(lambda Review: analyser.polarity_scores(Review))\n",
    "df['Compound'] = df['Scores'].apply(lambda score_dict: score_dict['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_verification</th>\n",
       "      <th>reviews</th>\n",
       "      <th>num_words</th>\n",
       "      <th>review_sentence</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>['I', 'travel', 'British', 'Airways', 'Sweden'...</td>\n",
       "      <td>196</td>\n",
       "      <td>I travel British Airways Sweden Los Angeles Lo...</td>\n",
       "      <td>{'neg': 0.094, 'neu': 0.858, 'pos': 0.048, 'co...</td>\n",
       "      <td>-0.8573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>['Food', 'lousy.', 'Who', 'plan', 'Asian', 'Hi...</td>\n",
       "      <td>54</td>\n",
       "      <td>Food lousy. Who plan Asian Hindu Vegetarian me...</td>\n",
       "      <td>{'neg': 0.187, 'neu': 0.664, 'pos': 0.149, 'co...</td>\n",
       "      <td>-0.5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>['Had', 'worst', 'experience.', 'The', 'flight...</td>\n",
       "      <td>59</td>\n",
       "      <td>Had worst experience. The flight London Toront...</td>\n",
       "      <td>{'neg': 0.174, 'neu': 0.745, 'pos': 0.082, 'co...</td>\n",
       "      <td>-0.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>['The', 'grind', 'staff', 'helpful.', 'Felt', ...</td>\n",
       "      <td>32</td>\n",
       "      <td>The grind staff helpful. Felt like want rush c...</td>\n",
       "      <td>{'neg': 0.113, 'neu': 0.65, 'pos': 0.237, 'com...</td>\n",
       "      <td>0.6124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>['Second', 'time', 'BA', 'Premium', 'Economy',...</td>\n",
       "      <td>50</td>\n",
       "      <td>Second time BA Premium Economy newer aircraft ...</td>\n",
       "      <td>{'neg': 0.048, 'neu': 0.562, 'pos': 0.391, 'co...</td>\n",
       "      <td>0.9713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_verification                                            reviews  \\\n",
       "0              False  ['I', 'travel', 'British', 'Airways', 'Sweden'...   \n",
       "1              False  ['Food', 'lousy.', 'Who', 'plan', 'Asian', 'Hi...   \n",
       "2               True  ['Had', 'worst', 'experience.', 'The', 'flight...   \n",
       "3               True  ['The', 'grind', 'staff', 'helpful.', 'Felt', ...   \n",
       "4               True  ['Second', 'time', 'BA', 'Premium', 'Economy',...   \n",
       "\n",
       "   num_words                                    review_sentence  \\\n",
       "0        196  I travel British Airways Sweden Los Angeles Lo...   \n",
       "1         54  Food lousy. Who plan Asian Hindu Vegetarian me...   \n",
       "2         59  Had worst experience. The flight London Toront...   \n",
       "3         32  The grind staff helpful. Felt like want rush c...   \n",
       "4         50  Second time BA Premium Economy newer aircraft ...   \n",
       "\n",
       "                                              Scores  Compound  \n",
       "0  {'neg': 0.094, 'neu': 0.858, 'pos': 0.048, 'co...   -0.8573  \n",
       "1  {'neg': 0.187, 'neu': 0.664, 'pos': 0.149, 'co...   -0.5574  \n",
       "2  {'neg': 0.174, 'neu': 0.745, 'pos': 0.082, 'co...   -0.6486  \n",
       "3  {'neg': 0.113, 'neu': 0.65, 'pos': 0.237, 'com...    0.6124  \n",
       "4  {'neg': 0.048, 'neu': 0.562, 'pos': 0.391, 'co...    0.9713  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment (score):\n",
    "    if score >= 0.5:\n",
    "        return 'Positive'\n",
    "    if (score > 0) and (score < 0.5):\n",
    "        return 'Neutral'\n",
    "    if score <= 0:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['Compound'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    502\n",
       "Negative    396\n",
       "Neutral     102\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shashank/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "doc2bow expects an array of unicode tokens on input, not a single string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dictionary \u001b[39m=\u001b[39m corpora\u001b[39m.\u001b[39;49mDictionary(df[\u001b[39m'\u001b[39;49m\u001b[39mreviews\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m \u001b[39m# Convert preprocessed data to bag of words corpus\u001b[39;00m\n\u001b[1;32m      4\u001b[0m bow_corpus \u001b[39m=\u001b[39m [dictionary\u001b[39m.\u001b[39mdoc2bow(doc) \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39m\u001b[39mreviews\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/corpora/dictionary.py:78\u001b[0m, in \u001b[0;36mDictionary.__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_nnz \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m documents \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_documents(documents, prune_at\u001b[39m=\u001b[39;49mprune_at)\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m     80\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m         msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_docs\u001b[39m}\u001b[39;00m\u001b[39m documents (total \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_pos\u001b[39m}\u001b[39;00m\u001b[39m corpus positions)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/corpora/dictionary.py:204\u001b[0m, in \u001b[0;36mDictionary.add_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    201\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39madding document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, docno, \u001b[39mself\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[39m# update Dictionary with the document\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdoc2bow(document, allow_update\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)  \u001b[39m# ignore the result, here we only care about updating token ids\u001b[39;00m\n\u001b[1;32m    206\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mbuilt \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m from \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m documents (total \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m corpus positions)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_docs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_pos)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/corpora/dictionary.py:241\u001b[0m, in \u001b[0;36mDictionary.doc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Convert `document` into the bag-of-words (BoW) format = list of `(token_id, token_count)` tuples.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(document, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdoc2bow expects an array of unicode tokens on input, not a single string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    243\u001b[0m \u001b[39m# Construct (word, frequency) mapping.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m counter \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: doc2bow expects an array of unicode tokens on input, not a single string"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mtype\u001b[39m(df[\u001b[39m'\u001b[39;49m\u001b[39mreviews\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m5\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/labelled_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
