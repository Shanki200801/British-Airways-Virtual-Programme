{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  Second time BA Premium Econ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Not Verified | I travelled with British Airway...\n",
       "1  Not Verified |  Food was lousy. Who ever is pl...\n",
       "2  ✅ Trip Verified | Had the worst experience. Th...\n",
       "3  ✅ Trip Verified |  The ground staff were not h...\n",
       "4  ✅ Trip Verified |  Second time BA Premium Econ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/BA_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[\"reviews\"].str.split('|').tolist(), columns=[\"trip_verification\",\"reviews\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'❎ Not Verified ': False, '✅ Trip Verified ': True, 'Not Verified ':False}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_verification</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>I travelled with British Airways from Sweden ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Food was lousy. Who ever is planning the Asi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Had the worst experience. The flight from Lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>The ground staff were not helpful. Felt like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Second time BA Premium Economy in a newer ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>True</td>\n",
       "      <td>Mumbai to London Heathrow. Disappointing exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>True</td>\n",
       "      <td>Delhi to London. Having read many negative r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>True</td>\n",
       "      <td>When you travel British Airways its like you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>True</td>\n",
       "      <td>British Airways gets plenty of well deserved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>True</td>\n",
       "      <td>BA First Class is not even that any more. St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trip_verification                                            reviews\n",
       "0                False   I travelled with British Airways from Sweden ...\n",
       "1                False    Food was lousy. Who ever is planning the Asi...\n",
       "2                 True   Had the worst experience. The flight from Lon...\n",
       "3                 True    The ground staff were not helpful. Felt like...\n",
       "4                 True    Second time BA Premium Economy in a newer ai...\n",
       "..                 ...                                                ...\n",
       "995               True    Mumbai to London Heathrow. Disappointing exp...\n",
       "996               True    Delhi to London. Having read many negative r...\n",
       "997               True   When you travel British Airways its like you ...\n",
       "998               True    British Airways gets plenty of well deserved...\n",
       "999               True    BA First Class is not even that any more. St...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     814\n",
       "False    186\n",
       "Name: trip_verification, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.trip_verification.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of stop words from the reviews\n",
    "import spacy\n",
    "#loading the english language small model of spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "sw_spacy = en.Defaults.stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'BA',\n",
       " 'British Airway',\n",
       " 'London',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'flight',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding common words which do not contribute to the sentiment of the review to the stope words\n",
    "set(list(sw_spacy)+['flight','BA','British Airway','London'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews'] = df['reviews'].str.split().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews'] = df['reviews'].apply(lambda x: [item for item in x if item not in sw_spacy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_verification</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>[I, travelled, British, Airways, Sweden, Los, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[Food, lousy., Who, planning, Asian, Hindu, Ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>[Had, worst, experience., The, flight, London,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>[The, ground, staff, helpful., Felt, like, wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[Second, time, BA, Premium, Economy, newer, ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>True</td>\n",
       "      <td>[Mumbai, London, Heathrow., Disappointing, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>True</td>\n",
       "      <td>[Delhi, London., Having, read, negative, revie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>True</td>\n",
       "      <td>[When, travel, British, Airways, like, lucky, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>True</td>\n",
       "      <td>[British, Airways, gets, plenty, deserved, kic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>True</td>\n",
       "      <td>[BA, First, Class, more., Starting, lounge, T3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trip_verification                                            reviews\n",
       "0                False  [I, travelled, British, Airways, Sweden, Los, ...\n",
       "1                False  [Food, lousy., Who, planning, Asian, Hindu, Ve...\n",
       "2                 True  [Had, worst, experience., The, flight, London,...\n",
       "3                 True  [The, ground, staff, helpful., Felt, like, wan...\n",
       "4                 True  [Second, time, BA, Premium, Economy, newer, ai...\n",
       "..                 ...                                                ...\n",
       "995               True  [Mumbai, London, Heathrow., Disappointing, exp...\n",
       "996               True  [Delhi, London., Having, read, negative, revie...\n",
       "997               True  [When, travel, British, Airways, like, lucky, ...\n",
       "998               True  [British, Airways, gets, plenty, deserved, kic...\n",
       "999               True  [BA, First, Class, more., Starting, lounge, T3...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "#The stop words are now removed from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/shashank/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Lemmatizing the reviews\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "df['reviews'] = df['reviews'].apply(lambda x: [wnl.lemmatize(item, pos='v') for item in x])\n",
    "df['reviews'] = df['reviews'].apply(lambda x: [wnl.lemmatize(item, pos='r') for item in x])\n",
    "df['reviews'] = df['reviews'].apply(lambda x: [wnl.lemmatize(item, pos='n') for item in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_lem_len = df['reviews'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews'].apply(lambda x: list(set(x)))\n",
    "after_lem_len = df['reviews'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = np.array(before_lem_len) - np.array(after_lem_len)\n",
    "diff.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['reviews'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_sentence'] = df['reviews'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_verification</th>\n",
       "      <th>reviews</th>\n",
       "      <th>num_words</th>\n",
       "      <th>review_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>[I, travel, British, Airways, Sweden, Los, Ang...</td>\n",
       "      <td>196</td>\n",
       "      <td>I travel British Airways Sweden Los Angeles Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[Food, lousy., Who, plan, Asian, Hindu, Vegeta...</td>\n",
       "      <td>54</td>\n",
       "      <td>Food lousy. Who plan Asian Hindu Vegetarian me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>[Had, worst, experience., The, flight, London,...</td>\n",
       "      <td>59</td>\n",
       "      <td>Had worst experience. The flight London Toront...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>[The, grind, staff, helpful., Felt, like, want...</td>\n",
       "      <td>32</td>\n",
       "      <td>The grind staff helpful. Felt like want rush c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[Second, time, BA, Premium, Economy, newer, ai...</td>\n",
       "      <td>50</td>\n",
       "      <td>Second time BA Premium Economy newer aircraft ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_verification                                            reviews  \\\n",
       "0              False  [I, travel, British, Airways, Sweden, Los, Ang...   \n",
       "1              False  [Food, lousy., Who, plan, Asian, Hindu, Vegeta...   \n",
       "2               True  [Had, worst, experience., The, flight, London,...   \n",
       "3               True  [The, grind, staff, helpful., Felt, like, want...   \n",
       "4               True  [Second, time, BA, Premium, Economy, newer, ai...   \n",
       "\n",
       "   num_words                                    review_sentence  \n",
       "0        196  I travel British Airways Sweden Los Angeles Lo...  \n",
       "1         54  Food lousy. Who plan Asian Hindu Vegetarian me...  \n",
       "2         59  Had worst experience. The flight London Toront...  \n",
       "3         32  The grind staff helpful. Felt like want rush c...  \n",
       "4         50  Second time BA Premium Economy newer aircraft ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/BA_reviews_lemmatized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They',\n",
       " 'change',\n",
       " 'Flights',\n",
       " 'Brussels',\n",
       " 'London',\n",
       " 'Heathrow',\n",
       " 'LAX',\n",
       " '4/16/2023.',\n",
       " 'We',\n",
       " 'pay',\n",
       " 'extra',\n",
       " 'choose',\n",
       " 'seats.',\n",
       " 'Since',\n",
       " 'cancel',\n",
       " 'honor',\n",
       " 'seat',\n",
       " 'bought,',\n",
       " 'seat',\n",
       " 'totally',\n",
       " 'different',\n",
       " 'seats.',\n",
       " 'I',\n",
       " 'ask',\n",
       " 'check',\n",
       " 'employee,',\n",
       " 'rude',\n",
       " 'tell',\n",
       " 'understand',\n",
       " 'different',\n",
       " 'flight.',\n",
       " 'From',\n",
       " 'London',\n",
       " 'LAX',\n",
       " 'worse,',\n",
       " 'airport',\n",
       " 'help',\n",
       " 'us.',\n",
       " 'Employees',\n",
       " 'BA',\n",
       " 'tell',\n",
       " 'return',\n",
       " 'day',\n",
       " 'flight',\n",
       " 'rent',\n",
       " 'hotel',\n",
       " 'terminal',\n",
       " '3',\n",
       " 'sleep',\n",
       " 'there.',\n",
       " 'Finally',\n",
       " 'employee',\n",
       " 'help',\n",
       " 'give',\n",
       " 'voucher',\n",
       " 'hotel.',\n",
       " 'It',\n",
       " 'nightmare',\n",
       " 'airline.',\n",
       " 'We',\n",
       " 'miss',\n",
       " 'day',\n",
       " 'work',\n",
       " 'BA',\n",
       " 'didn’t',\n",
       " 'return',\n",
       " 'money',\n",
       " 'pay',\n",
       " 'previous',\n",
       " 'choose',\n",
       " 'seats.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shashank/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.018*\"BA\" + 0.016*\"I\" + 0.014*\"flight\" + 0.011*\"The\" + 0.011*\"seat\" + 0.009*\"business\" + 0.008*\"class\" + 0.007*\"fly\" + 0.006*\"London\" + 0.006*\"service\"\n",
      "Topic: 1 \n",
      "Words: 0.038*\"I\" + 0.015*\"flight\" + 0.012*\"BA\" + 0.010*\"book\" + 0.008*\"cancel\" + 0.006*\"We\" + 0.006*\"British\" + 0.006*\"The\" + 0.005*\"airline\" + 0.004*\"Airways\"\n",
      "Topic: 2 \n",
      "Words: 0.014*\"The\" + 0.013*\"I\" + 0.010*\"seat\" + 0.008*\"BA\" + 0.008*\"food\" + 0.006*\"flight\" + 0.005*\"good\" + 0.005*\"service\" + 0.005*\"crew\" + 0.004*\"time\"\n",
      "Topic: 3 \n",
      "Words: 0.030*\"I\" + 0.012*\"BA\" + 0.011*\"seat\" + 0.008*\"flight\" + 0.008*\"pay\" + 0.007*\"The\" + 0.006*\"time\" + 0.006*\"London\" + 0.005*\"try\" + 0.005*\"hour\"\n",
      "Topic: 4 \n",
      "Words: 0.060*\"I\" + 0.024*\"flight\" + 0.012*\"The\" + 0.010*\"BA\" + 0.008*\"hour\" + 0.007*\"tell\" + 0.007*\"service\" + 0.006*\"London\" + 0.006*\"seat\" + 0.006*\"fly\"\n",
      "Topic: 5 \n",
      "Words: 0.019*\"flight\" + 0.013*\"I\" + 0.012*\"The\" + 0.010*\"British\" + 0.007*\"service\" + 0.007*\"BA\" + 0.007*\"seat\" + 0.007*\"Airways\" + 0.005*\"check\" + 0.005*\"food\"\n",
      "Topic: 6 \n",
      "Words: 0.027*\"I\" + 0.022*\"The\" + 0.015*\"seat\" + 0.011*\"BA\" + 0.010*\"flight\" + 0.008*\"service\" + 0.008*\"cabin\" + 0.007*\"good\" + 0.007*\"crew\" + 0.007*\"-\"\n",
      "Topic: 7 \n",
      "Words: 0.016*\"The\" + 0.016*\"flight\" + 0.013*\"I\" + 0.008*\"seat\" + 0.008*\"BA\" + 0.007*\"crew\" + 0.006*\"London\" + 0.005*\"-\" + 0.004*\"good\" + 0.004*\"hour\"\n",
      "Topic: 8 \n",
      "Words: 0.025*\"I\" + 0.022*\"flight\" + 0.015*\"The\" + 0.010*\"BA\" + 0.007*\"seat\" + 0.006*\"fly\" + 0.006*\"We\" + 0.006*\"London\" + 0.005*\"British\" + 0.004*\"time\"\n",
      "Topic: 9 \n",
      "Words: 0.009*\"staff\" + 0.009*\"We\" + 0.009*\"The\" + 0.008*\"flight\" + 0.008*\"luggage\" + 0.006*\"BA\" + 0.006*\"I\" + 0.004*\"Airways\" + 0.004*\"airport\" + 0.004*\"check\"\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
